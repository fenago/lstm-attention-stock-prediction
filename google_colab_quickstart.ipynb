{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üöÄ LSTM Stock Prediction - Quick Start (Google Colab)\n",
    "\n",
    "**One-click stock prediction with LSTM + Attention mechanism!**\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fenago/lstm-attention-stock-prediction/blob/main/google_colab_quickstart.ipynb)\n",
    "\n",
    "**Author:** Dr. Ernesto Lee | [drlee.io](https://drlee.io)  \n",
    "**GitHub:** [fenago/lstm-attention-stock-prediction](https://github.com/fenago/lstm-attention-stock-prediction)\n",
    "\n",
    "---\n",
    "\n",
    "## What This Notebook Does\n",
    "\n",
    "1. ‚úÖ Installs all dependencies\n",
    "2. ‚úÖ Fetches stock data (default: AAPL)\n",
    "3. ‚úÖ Trains LSTM model with attention\n",
    "4. ‚úÖ Shows predictions vs actual prices\n",
    "5. ‚úÖ Predicts next 4 trading days\n",
    "6. ‚úÖ Downloads trained model\n",
    "\n",
    "**Total Runtime:** ~5-10 minutes on Colab\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Quick Start\n",
    "\n",
    "Just click **Runtime ‚Üí Run all** and wait!\n",
    "\n",
    "Or run each cell step-by-step ‚¨áÔ∏è\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install"
   },
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-code"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tensorflow keras yfinance numpy pandas matplotlib scikit-learn -q\n",
    "print(\"‚úÖ All packages installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imports"
   },
   "source": [
    "## Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports-code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Dropout, BatchNormalization, AdditiveAttention, Concatenate, Lambda\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"‚úÖ TensorFlow {tf.__version__} ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## Step 3: Configuration\n",
    "\n",
    "**üí° Tip:** Change `TICKER` to predict any stock!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config-code"
   },
   "outputs": [],
   "source": [
    "#@title Configuration { run: \"auto\" }\n",
    "TICKER = \"AAPL\" #@param {type:\"string\"}\n",
    "START_DATE = \"2020-01-01\" #@param {type:\"date\"}\n",
    "END_DATE = \"2024-01-01\" #@param {type:\"date\"}\n",
    "SEQUENCE_LENGTH = 60 #@param {type:\"slider\", min:30, max:120, step:10}\n",
    "EPOCHS = 50 #@param {type:\"slider\", min:20, max:100, step:10}\n",
    "\n",
    "print(f\"üìä Stock: {TICKER}\")\n",
    "print(f\"üìÖ Date Range: {START_DATE} to {END_DATE}\")\n",
    "print(f\"üî¢ Sequence Length: {SEQUENCE_LENGTH} days\")\n",
    "print(f\"üîÑ Max Epochs: {EPOCHS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fetch-data"
   },
   "source": [
    "## Step 4: Fetch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fetch-code"
   },
   "outputs": [],
   "source": [
    "print(f\"Fetching {TICKER} data...\")\n",
    "data = yf.download(TICKER, start=START_DATE, end=END_DATE)\n",
    "data = data.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "print(f\"‚úÖ Fetched {len(data)} trading days\")\n",
    "print(f\"üìà Price range: ${data['Close'].min():.2f} - ${data['Close'].max():.2f}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(data.index, data['Close'], linewidth=2)\n",
    "plt.title(f'{TICKER} Stock Price History', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prepare"
   },
   "source": [
    "## Step 5: Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prepare-code"
   },
   "outputs": [],
   "source": [
    "# Extract Close prices\n",
    "close_prices = data['Close'].values.reshape(-1, 1)\n",
    "\n",
    "# Split data (80/20)\n",
    "split_idx = int(len(close_prices) * 0.8)\n",
    "train_data = close_prices[:split_idx]\n",
    "test_data = close_prices[split_idx:]\n",
    "\n",
    "# Scale data (FIT on train only!)\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train_data)\n",
    "test_scaled = scaler.transform(test_data)\n",
    "\n",
    "# Create sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(seq_length, len(data)):\n",
    "        X.append(data[i-seq_length:i, 0])\n",
    "        y.append(data[i, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = create_sequences(train_scaled, SEQUENCE_LENGTH)\n",
    "\n",
    "# For test, combine last sequence from train\n",
    "combined = np.concatenate([train_scaled[-SEQUENCE_LENGTH:], test_scaled])\n",
    "X_test, y_test = create_sequences(combined, SEQUENCE_LENGTH)\n",
    "\n",
    "# Reshape for LSTM [samples, time steps, features]\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "print(f\"‚úÖ Training data: {X_train.shape}\")\n",
    "print(f\"‚úÖ Testing data: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "build-model"
   },
   "source": [
    "## Step 6: Build Model with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "build-code"
   },
   "outputs": [],
   "source": [
    "# Build model with attention\n",
    "inputs = Input(shape=(SEQUENCE_LENGTH, 1))\n",
    "\n",
    "# LSTM layers\n",
    "lstm1 = LSTM(64, return_sequences=True)(inputs)\n",
    "lstm1 = Dropout(0.2)(lstm1)\n",
    "lstm1 = BatchNormalization()(lstm1)\n",
    "\n",
    "lstm2 = LSTM(32, return_sequences=True)(lstm1)\n",
    "lstm2 = Dropout(0.2)(lstm2)\n",
    "lstm2 = BatchNormalization()(lstm2)\n",
    "\n",
    "# Attention\n",
    "attention = AdditiveAttention()([lstm2, lstm2])\n",
    "concat = Concatenate()([lstm2, attention])\n",
    "pooled = Lambda(lambda x: tf.reduce_mean(x, axis=1))(concat)\n",
    "\n",
    "# Output\n",
    "dense = Dense(32, activation='relu')(pooled)\n",
    "dense = Dropout(0.2)(dense)\n",
    "outputs = Dense(1)(dense)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "print(f\"‚úÖ Model built: {model.count_params():,} parameters\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train"
   },
   "source": [
    "## Step 7: Train Model\n",
    "\n",
    "**‚è±Ô∏è This may take 3-5 minutes...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train-code"
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "val_idx = int(len(X_train) * 0.8)\n",
    "X_train_final = X_train[:val_idx]\n",
    "y_train_final = y_train[:val_idx]\n",
    "X_val = X_train[val_idx:]\n",
    "y_val = y_train[val_idx:]\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_final, y_train_final,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plot-training"
   },
   "source": [
    "## Step 8: Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot-training-code"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "ax[0].plot(history.history['loss'], label='Train')\n",
    "ax[0].plot(history.history['val_loss'], label='Validation')\n",
    "ax[0].set_title('Loss')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].legend()\n",
    "ax[0].grid(True, alpha=0.3)\n",
    "\n",
    "ax[1].plot(history.history['mae'], label='Train')\n",
    "ax[1].plot(history.history['val_mae'], label='Validation')\n",
    "ax[1].set_title('MAE')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].legend()\n",
    "ax[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluate"
   },
   "source": [
    "## Step 9: Evaluate & Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate-code"
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "predictions_scaled = model.predict(X_test)\n",
    "\n",
    "# Inverse transform\n",
    "predictions = scaler.inverse_transform(predictions_scaled)\n",
    "actuals = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Metrics\n",
    "mae = mean_absolute_error(actuals, predictions)\n",
    "rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "r2 = r2_score(actuals, predictions)\n",
    "\n",
    "print(\"üìä Test Set Performance:\")\n",
    "print(f\"  MAE:  ${mae:.2f}\")\n",
    "print(f\"  RMSE: ${rmse:.2f}\")\n",
    "print(f\"  R¬≤:   {r2:.4f}\")\n",
    "\n",
    "# Get test dates\n",
    "test_dates = data.index[split_idx + SEQUENCE_LENGTH:]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(data.index[-200:], data['Close'].values[-200:], label='Historical', alpha=0.7, linewidth=2)\n",
    "plt.plot(test_dates, actuals, label='Actual (Test)', color='green', marker='o', markersize=3)\n",
    "plt.plot(test_dates, predictions, label='Predicted (Test)', color='red', marker='x', markersize=3)\n",
    "plt.axvline(x=test_dates[0], color='black', linestyle='--', label='Train/Test Split')\n",
    "plt.title(f'{TICKER} Stock Prediction - LSTM with Attention', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "future"
   },
   "source": [
    "## Step 10: Predict Future (Next 4 Days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "future-code"
   },
   "outputs": [],
   "source": [
    "# Get last 60 days\n",
    "last_sequence = close_prices[-SEQUENCE_LENGTH:]\n",
    "last_sequence_scaled = scaler.transform(last_sequence)\n",
    "\n",
    "# Predict next 4 days iteratively\n",
    "future_predictions = []\n",
    "current_sequence = last_sequence_scaled.copy()\n",
    "\n",
    "for i in range(4):\n",
    "    current_batch = current_sequence.reshape(1, SEQUENCE_LENGTH, 1)\n",
    "    next_pred = model.predict(current_batch, verbose=0)\n",
    "    future_predictions.append(next_pred[0, 0])\n",
    "    current_sequence = np.append(current_sequence[1:], next_pred[0, 0])\n",
    "\n",
    "# Inverse transform\n",
    "future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))\n",
    "\n",
    "last_price = close_prices[-1][0]\n",
    "last_date = data.index[-1]\n",
    "\n",
    "print(f\"\\nüîÆ Future Predictions from {last_date.date()}:\")\n",
    "print(f\"Last known price: ${last_price:.2f}\\n\")\n",
    "\n",
    "for i, pred in enumerate(future_predictions, 1):\n",
    "    change = pred[0] - last_price\n",
    "    pct_change = (change / last_price) * 100\n",
    "    direction = \"‚¨ÜÔ∏è\" if change > 0 else \"‚¨áÔ∏è\"\n",
    "    print(f\"Day {i}: ${pred[0]:.2f} ({change:+.2f}, {pct_change:+.2f}%) {direction}\")\n",
    "    last_price = pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "save"
   },
   "source": [
    "## Step 11: Save & Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save-code"
   },
   "outputs": [],
   "source": [
    "# Save model and scaler\n",
    "model.save('lstm_model.h5')\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"‚úÖ Model saved!\")\n",
    "\n",
    "# Download files (Colab only)\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('lstm_model.h5')\n",
    "    files.download('scaler.pkl')\n",
    "    print(\"üì• Files downloaded to your computer!\")\n",
    "except:\n",
    "    print(\"üíæ Files saved in current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "---\n",
    "\n",
    "## üéâ Done!\n",
    "\n",
    "You successfully:\n",
    "- ‚úÖ Trained an LSTM model with attention\n",
    "- ‚úÖ Evaluated on test data\n",
    "- ‚úÖ Made future predictions\n",
    "- ‚úÖ Downloaded the trained model\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Try different stocks** - Change `TICKER` and rerun\n",
    "2. **Advanced version** - Check out the full tutorial with 35 technical indicators\n",
    "3. **Learn more** - Read the complete Medium article\n",
    "4. **Star the repo** - [github.com/fenago/lstm-attention-stock-prediction](https://github.com/fenago/lstm-attention-stock-prediction)\n",
    "\n",
    "---\n",
    "\n",
    "## Resources\n",
    "\n",
    "- üìñ [GitHub Repository](https://github.com/fenago/lstm-attention-stock-prediction)\n",
    "- üìù [Medium Article](https://drlee.io)\n",
    "- üíª [Advanced Tutorial Notebook](https://github.com/fenago/lstm-attention-stock-prediction/blob/main/basic_tutorial.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Disclaimer\n",
    "\n",
    "**This is for educational purposes only.** Do not use for actual trading without proper risk management and professional financial advice.\n",
    "\n",
    "---\n",
    "\n",
    "**Created by Dr. Ernesto Lee | [drlee.io](https://drlee.io)**\n",
    "\n",
    "If this helped you, please ‚≠ê the repo!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "LSTM Stock Prediction - Quick Start",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
