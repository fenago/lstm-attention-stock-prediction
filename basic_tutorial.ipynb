{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM with Attention for Stock Prediction - Basic Tutorial\n",
    "\n",
    "This notebook implements the corrected LSTM with attention mechanism for stock price prediction.\n",
    "\n",
    "**Author:** Dr. Ernesto Lee | [drlee.io](https://drlee.io)\n",
    "\n",
    "**Repository:** [github.com/fenago/lstm-attention-stock-prediction](https://github.com/fenago/lstm-attention-stock-prediction)\n",
    "\n",
    "---\n",
    "\n",
    "## What's Fixed in This Version?\n",
    "\n",
    "✅ Working attention mechanism (Functional API)\n",
    "✅ Proper scaler handling (no data leakage)\n",
    "✅ Correct data splitting\n",
    "✅ Production-ready code\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "Install all required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow keras yfinance numpy pandas matplotlib scikit-learn -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Dropout, BatchNormalization\n",
    "from keras.layers import AdditiveAttention, Concatenate, Lambda\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stock Predictor Class\n",
    "\n",
    "Complete implementation with all bug fixes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockPredictorLSTMAttention:\n",
    "    \"\"\"\n",
    "    LSTM with Attention Mechanism for Stock Price Prediction\n",
    "    \n",
    "    This corrected implementation fixes all issues from the original article.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sequence_length=60, prediction_days=4, features=['Close']):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.prediction_days = prediction_days\n",
    "        self.features = features\n",
    "        self.n_features = len(features)\n",
    "        self.scaler = None\n",
    "        self.model = None\n",
    "\n",
    "    def fetch_data(self, ticker='AAPL', start_date='2020-01-01', end_date='2024-01-01'):\n",
    "        \"\"\"Fetch stock data from Yahoo Finance\"\"\"\n",
    "        print(f\"Fetching {ticker} data from {start_date} to {end_date}...\")\n",
    "        data = yf.download(ticker, start=start_date, end=end_date)\n",
    "        data = data.fillna(method='ffill').fillna(method='bfill')\n",
    "        print(f\"Fetched {len(data)} trading days\")\n",
    "        return data\n",
    "\n",
    "    def prepare_data(self, data, train_split=0.8):\n",
    "        \"\"\"Prepare data with PROPER train/test split and NO look-ahead bias\"\"\"\n",
    "        feature_data = data[self.features].values\n",
    "\n",
    "        # Split BEFORE scaling (critical!)\n",
    "        split_idx = int(len(feature_data) * train_split)\n",
    "        train_data = feature_data[:split_idx]\n",
    "        test_data = feature_data[split_idx:]\n",
    "\n",
    "        # Fit scaler on training data ONLY\n",
    "        self.scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        train_scaled = self.scaler.fit_transform(train_data)\n",
    "        test_scaled = self.scaler.transform(test_data)\n",
    "\n",
    "        # Create sequences\n",
    "        X_train, y_train = self._create_sequences(train_scaled)\n",
    "        combined_data = np.concatenate([train_scaled[-self.sequence_length:], test_scaled])\n",
    "        X_test, y_test = self._create_sequences(combined_data)\n",
    "\n",
    "        test_dates = data.index[split_idx + self.sequence_length:]\n",
    "\n",
    "        print(f\"Training sequences: {X_train.shape}\")\n",
    "        print(f\"Testing sequences: {X_test.shape}\")\n",
    "\n",
    "        return X_train, y_train, X_test, y_test, test_dates\n",
    "\n",
    "    def _create_sequences(self, data):\n",
    "        \"\"\"Create sequences for LSTM training\"\"\"\n",
    "        X, y = [], []\n",
    "        for i in range(self.sequence_length, len(data)):\n",
    "            X.append(data[i - self.sequence_length:i])\n",
    "            y.append(data[i, :])\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    def build_model(self, lstm_units=[64, 32], dropout_rate=0.2):\n",
    "        \"\"\"Build LSTM model with WORKING attention mechanism\"\"\"\n",
    "        inputs = Input(shape=(self.sequence_length, self.n_features))\n",
    "\n",
    "        # First LSTM layer\n",
    "        lstm_out1 = LSTM(lstm_units[0], return_sequences=True)(inputs)\n",
    "        lstm_out1 = Dropout(dropout_rate)(lstm_out1)\n",
    "        lstm_out1 = BatchNormalization()(lstm_out1)\n",
    "\n",
    "        # Second LSTM layer\n",
    "        lstm_out2 = LSTM(lstm_units[1], return_sequences=True)(lstm_out1)\n",
    "        lstm_out2 = Dropout(dropout_rate)(lstm_out2)\n",
    "        lstm_out2 = BatchNormalization()(lstm_out2)\n",
    "\n",
    "        # Attention mechanism (PROPERLY IMPLEMENTED)\n",
    "        attention_out = AdditiveAttention()([lstm_out2, lstm_out2])\n",
    "\n",
    "        # Combine attention output with LSTM output\n",
    "        concat = Concatenate()([lstm_out2, attention_out])\n",
    "\n",
    "        # Global pooling\n",
    "        pooled = Lambda(lambda x: tf.reduce_mean(x, axis=1))(concat)\n",
    "\n",
    "        # Dense layers\n",
    "        dense1 = Dense(32, activation='relu')(pooled)\n",
    "        dense1 = Dropout(dropout_rate)(dense1)\n",
    "\n",
    "        # Output layer\n",
    "        outputs = Dense(self.n_features)(dense1)\n",
    "\n",
    "        # Create model\n",
    "        model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "        # Compile\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "\n",
    "        self.model = model\n",
    "        return model\n",
    "\n",
    "    def train(self, X_train, y_train, X_val=None, y_val=None, epochs=100, batch_size=32, verbose=1):\n",
    "        \"\"\"Train the model\"\"\"\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss' if X_val is not None else 'loss',\n",
    "                         patience=15, restore_best_weights=True, verbose=1),\n",
    "            ReduceLROnPlateau(monitor='val_loss' if X_val is not None else 'loss',\n",
    "                            factor=0.5, patience=7, min_lr=1e-7, verbose=1)\n",
    "        ]\n",
    "\n",
    "        validation_data = (X_val, y_val) if X_val is not None else None\n",
    "\n",
    "        history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=validation_data,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=callbacks,\n",
    "            verbose=verbose\n",
    "        )\n",
    "\n",
    "        return history\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"Evaluate model performance\"\"\"\n",
    "        predictions = self.model.predict(X_test)\n",
    "\n",
    "        predictions_original = self.scaler.inverse_transform(predictions)\n",
    "        y_test_original = self.scaler.inverse_transform(y_test)\n",
    "\n",
    "        metrics = {}\n",
    "        for i, feature in enumerate(self.features):\n",
    "            mae = mean_absolute_error(y_test_original[:, i], predictions_original[:, i])\n",
    "            rmse = np.sqrt(mean_squared_error(y_test_original[:, i], predictions_original[:, i]))\n",
    "            r2 = r2_score(y_test_original[:, i], predictions_original[:, i])\n",
    "\n",
    "            metrics[feature] = {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "            print(f\"\\n{feature}:\")\n",
    "            print(f\"  MAE:  ${mae:.2f}\")\n",
    "            print(f\"  RMSE: ${rmse:.2f}\")\n",
    "            print(f\"  R²:   {r2:.4f}\")\n",
    "\n",
    "        return metrics, predictions_original, y_test_original\n",
    "\n",
    "    def predict_next_n_days(self, data, n_days=4):\n",
    "        \"\"\"Predict next N days using the SAVED scaler\"\"\"\n",
    "        last_sequence = data[self.features].values[-self.sequence_length:]\n",
    "        last_sequence_scaled = self.scaler.transform(last_sequence)\n",
    "\n",
    "        predictions = []\n",
    "        current_sequence = last_sequence_scaled.copy()\n",
    "\n",
    "        for _ in range(n_days):\n",
    "            current_batch = current_sequence.reshape(1, self.sequence_length, self.n_features)\n",
    "            next_pred = self.model.predict(current_batch, verbose=0)\n",
    "            predictions.append(next_pred[0])\n",
    "            current_sequence = np.vstack([current_sequence[1:], next_pred[0]])\n",
    "\n",
    "        predictions_original = self.scaler.inverse_transform(np.array(predictions))\n",
    "        return predictions_original\n",
    "\n",
    "    def save_model(self, model_path='lstm_model.h5', scaler_path='scaler.pkl'):\n",
    "        \"\"\"Save model and scaler\"\"\"\n",
    "        self.model.save(model_path)\n",
    "        with open(scaler_path, 'wb') as f:\n",
    "            pickle.dump(self.scaler, f)\n",
    "        print(f\"Model and scaler saved!\")\n",
    "\n",
    "    def load_model(self, model_path='lstm_model.h5', scaler_path='scaler.pkl'):\n",
    "        \"\"\"Load saved model and scaler\"\"\"\n",
    "        self.model = keras.models.load_model(model_path)\n",
    "        with open(scaler_path, 'rb') as f:\n",
    "            self.scaler = pickle.load(f)\n",
    "        print(f\"Model and scaler loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "TICKER = 'AAPL'  # Change to your preferred stock\n",
    "START_DATE = '2020-01-01'\n",
    "END_DATE = '2024-01-01'\n",
    "SEQUENCE_LENGTH = 60\n",
    "PREDICTION_DAYS = 4\n",
    "FEATURES = ['Close']  # Start with Close only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize and Fetch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize predictor\n",
    "predictor = StockPredictorLSTMAttention(\n",
    "    sequence_length=SEQUENCE_LENGTH,\n",
    "    prediction_days=PREDICTION_DAYS,\n",
    "    features=FEATURES\n",
    ")\n",
    "\n",
    "# Fetch data\n",
    "data = predictor.fetch_data(TICKER, START_DATE, END_DATE)\n",
    "\n",
    "# Display first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data (proper splitting!)\n",
    "X_train, y_train, X_test, y_test, test_dates = predictor.prepare_data(data, train_split=0.8)\n",
    "\n",
    "# Split training data for validation\n",
    "val_split = 0.2\n",
    "val_idx = int(len(X_train) * (1 - val_split))\n",
    "X_train_final = X_train[:val_idx]\n",
    "y_train_final = y_train[:val_idx]\n",
    "X_val = X_train[val_idx:]\n",
    "y_val = y_train[val_idx:]\n",
    "\n",
    "print(f\"\\nFinal split:\")\n",
    "print(f\"  Training: {X_train_final.shape[0]} samples\")\n",
    "print(f\"  Validation: {X_val.shape[0]} samples\")\n",
    "print(f\"  Test: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = predictor.build_model(lstm_units=[64, 32], dropout_rate=0.2)\n",
    "print(f\"Total parameters: {model.count_params():,}\")\n",
    "\n",
    "# Show model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "history = predictor.train(\n",
    "    X_train_final, y_train_final,\n",
    "    X_val, y_val,\n",
    "    epochs=100,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history.history['loss'], label='Train Loss')\n",
    "axes[0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "axes[0].set_title('Model Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# MAE\n",
    "axes[1].plot(history.history['mae'], label='Train MAE')\n",
    "axes[1].plot(history.history['val_mae'], label='Validation MAE')\n",
    "axes[1].set_title('Model MAE')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "metrics, predictions, actuals = predictor.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions\n",
    "plt.figure(figsize=(16, 7))\n",
    "\n",
    "# Plot last 200 days\n",
    "plt.plot(data.index[-200:], data['Close'].values[-200:],\n",
    "         label='Historical Price', color='blue', alpha=0.7, linewidth=2)\n",
    "\n",
    "# Plot test predictions\n",
    "plt.plot(test_dates, actuals[:, 0],\n",
    "         label='Actual (Test)', color='green', marker='o', markersize=4)\n",
    "\n",
    "plt.plot(test_dates, predictions[:, 0],\n",
    "         label='Predicted (Test)', color='red', marker='x', markersize=5)\n",
    "\n",
    "plt.axvline(x=test_dates[0], color='black', linestyle='--', linewidth=2,\n",
    "            label='Train/Test Split', alpha=0.6)\n",
    "\n",
    "plt.title(f'{TICKER} Stock Price Prediction - LSTM with Attention', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=13)\n",
    "plt.ylabel('Price ($)', fontsize=13)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Predict Future Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict next 4 days\n",
    "future_predictions = predictor.predict_next_n_days(data, n_days=4)\n",
    "\n",
    "last_date = data.index[-1]\n",
    "last_price = data['Close'].iloc[-1]\n",
    "\n",
    "print(f\"Last known date: {last_date.date()}\")\n",
    "print(f\"Last known price: ${last_price:.2f}\")\n",
    "print(\"\\nFuture Predictions:\")\n",
    "\n",
    "for i, pred in enumerate(future_predictions, 1):\n",
    "    pred_price = pred[0]\n",
    "    change = pred_price - last_price\n",
    "    pct_change = (change / last_price) * 100\n",
    "    print(f\"Day {i}: ${pred_price:.2f} (change: ${change:+.2f}, {pct_change:+.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and scaler\n",
    "predictor.save_model('aapl_lstm_model.h5', 'aapl_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Load and Use Saved Model (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load saved model later\n",
    "# new_predictor = StockPredictorLSTMAttention(sequence_length=60, prediction_days=4, features=['Close'])\n",
    "# new_predictor.load_model('aapl_lstm_model.h5', 'aapl_scaler.pkl')\n",
    "# predictions = new_predictor.predict_next_n_days(data, n_days=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Try different stocks** - Change the `TICKER` variable\n",
    "2. **Add more features** - Use `features=['Open', 'High', 'Low', 'Close', 'Volume']`\n",
    "3. **Advanced version** - Check out the advanced tutorial with 35 technical indicators\n",
    "4. **Deploy** - Use the saved model for production\n",
    "\n",
    "---\n",
    "\n",
    "## Resources\n",
    "\n",
    "- **GitHub Repository:** [fenago/lstm-attention-stock-prediction](https://github.com/fenago/lstm-attention-stock-prediction)\n",
    "- **Medium Article:** Complete tutorial with explanations\n",
    "- **Advanced Tutorial:** Next notebook with technical indicators\n",
    "\n",
    "---\n",
    "\n",
    "## Disclaimer\n",
    "\n",
    "⚠️ **This code is for educational purposes only.** Do not use for actual trading without proper risk management and professional financial advice.\n",
    "\n",
    "---\n",
    "\n",
    "**Dr. Ernesto Lee | drlee.io**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
